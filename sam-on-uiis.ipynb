{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ced4dc9",
   "metadata": {
    "papermill": {
     "duration": 0.004352,
     "end_time": "2024-12-13T18:12:16.698002",
     "exception": false,
     "start_time": "2024-12-13T18:12:16.693650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88eb1e03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:16.710339Z",
     "iopub.status.busy": "2024-12-13T18:12:16.709668Z",
     "iopub.status.idle": "2024-12-13T18:12:26.163697Z",
     "shell.execute_reply": "2024-12-13T18:12:26.162802Z"
    },
    "papermill": {
     "duration": 9.462466,
     "end_time": "2024-12-13T18:12:26.165768",
     "exception": false,
     "start_time": "2024-12-13T18:12:16.703302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\r\n",
      "Requirement already satisfied: segment-anything in /opt/conda/lib/python3.10/site-packages (1.0)\r\n",
      "Collecting pycocotools\r\n",
      "  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\r\n",
      "Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pycocotools\r\n",
      "Successfully installed pycocotools-2.0.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision segment-anything pycocotools pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ccaf49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:26.174745Z",
     "iopub.status.busy": "2024-12-13T18:12:26.174448Z",
     "iopub.status.idle": "2024-12-13T18:12:30.561601Z",
     "shell.execute_reply": "2024-12-13T18:12:30.560905Z"
    },
    "papermill": {
     "duration": 4.393808,
     "end_time": "2024-12-13T18:12:30.563584",
     "exception": false,
     "start_time": "2024-12-13T18:12:26.169776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from segment_anything import sam_model_registry\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957f77c",
   "metadata": {
    "papermill": {
     "duration": 0.003569,
     "end_time": "2024-12-13T18:12:30.571076",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.567507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f60384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:30.580493Z",
     "iopub.status.busy": "2024-12-13T18:12:30.580145Z",
     "iopub.status.idle": "2024-12-13T18:12:30.584163Z",
     "shell.execute_reply": "2024-12-13T18:12:30.583517Z"
    },
    "papermill": {
     "duration": 0.009819,
     "end_time": "2024-12-13T18:12:30.585573",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.575754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"/kaggle/input/sam/other/default/1/sam_vit_l_0b3195.pth\"\n",
    "TRAIN_ROOT = '/kaggle/input/underwaterimageinstancesegmentation/UIIS/UDW/train'\n",
    "TRAIN_ANN = '/kaggle/input/underwaterimageinstancesegmentation/UIIS/UDW/annotations/train.json'\n",
    "VAL_ROOT = '/kaggle/input/underwaterimageinstancesegmentation/UIIS/UDW/val'\n",
    "VAL_ANN = '/kaggle/input/underwaterimageinstancesegmentation/UIIS/UDW/annotations/val.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d6c8f0",
   "metadata": {
    "papermill": {
     "duration": 0.00348,
     "end_time": "2024-12-13T18:12:30.592607",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.589127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c467ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:30.600769Z",
     "iopub.status.busy": "2024-12-13T18:12:30.600500Z",
     "iopub.status.idle": "2024-12-13T18:12:30.608553Z",
     "shell.execute_reply": "2024-12-13T18:12:30.607757Z"
    },
    "papermill": {
     "duration": 0.01401,
     "end_time": "2024-12-13T18:12:30.610195",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.596185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnderwaterInstanceDataset(Dataset):\n",
    "    def __init__(self, root_dir, ann_file, transform=None, image_size=(1024, 1024)):\n",
    "        self.root = root_dir\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        self.transform = transform\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        \n",
    "        # Load image\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(self.root, img_info['file_name'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Resize image\n",
    "        image = image.resize(self.image_size, Image.Resampling.BILINEAR)\n",
    "        \n",
    "        # Create mask\n",
    "        masks = []\n",
    "        labels = []\n",
    "        for ann in anns:\n",
    "            mask = self.coco.annToMask(ann)\n",
    "            # Resize mask\n",
    "            mask = Image.fromarray(mask)\n",
    "            mask = mask.resize(self.image_size, Image.Resampling.NEAREST)\n",
    "            mask = np.array(mask)\n",
    "            masks.append(mask)\n",
    "            labels.append(ann['category_id'])\n",
    "            \n",
    "        # Stack masks along new dimension\n",
    "        if len(masks) > 0:\n",
    "            masks = np.stack(masks, axis=0)\n",
    "        else:\n",
    "            masks = np.zeros((1, *self.image_size), dtype=np.uint8)\n",
    "            labels = [0]  # Add dummy label\n",
    "            \n",
    "        # Convert to tensors\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            masks = torch.from_numpy(masks).float()\n",
    "            \n",
    "        return image, masks, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6399666c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:30.618406Z",
     "iopub.status.busy": "2024-12-13T18:12:30.618006Z",
     "iopub.status.idle": "2024-12-13T18:12:30.623732Z",
     "shell.execute_reply": "2024-12-13T18:12:30.623008Z"
    },
    "papermill": {
     "duration": 0.011457,
     "end_time": "2024-12-13T18:12:30.625252",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.613795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    \n",
    "    # Find max number of masks across batch\n",
    "    max_masks = max(item[1].shape[0] for item in batch)\n",
    "    \n",
    "    # Pad masks and labels to max size\n",
    "    padded_masks = []\n",
    "    padded_labels = []\n",
    "    \n",
    "    for _, masks, labels in batch:\n",
    "        num_masks = masks.shape[0]\n",
    "        \n",
    "        # Create padding for masks\n",
    "        if num_masks < max_masks:\n",
    "            padding = torch.zeros((max_masks - num_masks, masks.shape[1], masks.shape[2]))\n",
    "            padded_mask = torch.cat([masks, padding], dim=0)\n",
    "            \n",
    "            # Create padding for labels \n",
    "            label_padding = torch.zeros(max_masks - num_masks)\n",
    "            padded_label = torch.cat([labels, label_padding])\n",
    "        else:\n",
    "            padded_mask = masks\n",
    "            padded_label = labels\n",
    "            \n",
    "        padded_masks.append(padded_mask)\n",
    "        padded_labels.append(padded_label)\n",
    "    \n",
    "    # Stack padded masks and labels\n",
    "    masks = torch.stack(padded_masks)\n",
    "    labels = torch.stack(padded_labels)\n",
    "    \n",
    "    return images, masks, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af6b663",
   "metadata": {
    "papermill": {
     "duration": 0.003312,
     "end_time": "2024-12-13T18:12:30.632116",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.628804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770dd5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:30.640308Z",
     "iopub.status.busy": "2024-12-13T18:12:30.640068Z",
     "iopub.status.idle": "2024-12-13T18:12:30.651398Z",
     "shell.execute_reply": "2024-12-13T18:12:30.650754Z"
    },
    "papermill": {
     "duration": 0.01737,
     "end_time": "2024-12-13T18:12:30.652988",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.635618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch.cuda.amp as amp\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "class SAMFinetune(nn.Module):\n",
    "    def __init__(self, checkpoint_path, model_type=\"vit_l\"):\n",
    "        super().__init__()\n",
    "        self.sam = sam_model_registry[model_type](checkpoint=checkpoint_path)\n",
    "        \n",
    "        # Enable gradient checkpointing\n",
    "        self.sam.image_encoder.use_gradient_checkpointing = True\n",
    "        self.sam.mask_decoder.transformer.use_gradient_checkpointing = True\n",
    "        \n",
    "        # Freeze image encoder\n",
    "        for param in self.sam.image_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Freeze prompt encoder\n",
    "        for param in self.sam.prompt_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Only train mask decoder\n",
    "        for param in self.sam.mask_decoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, image, masks=None):\n",
    "        # Clear cache before forward pass\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        batch_size = image.shape[0]\n",
    "        num_instances = masks.shape[1] if masks is not None else 1\n",
    "        \n",
    "        # Get image embeddings with gradient checkpointing\n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_embeddings = checkpoint(self.sam.image_encoder, image)\n",
    "        \n",
    "        final_masks = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            curr_masks = masks[b] if masks is not None else None\n",
    "            curr_embeddings = image_embeddings[b:b+1]\n",
    "            \n",
    "            instance_masks = []\n",
    "            \n",
    "            for i in range(num_instances):\n",
    "                if curr_masks is not None:\n",
    "                    mask = curr_masks[i]\n",
    "                    if mask.sum() > 0:\n",
    "                        y_indices, x_indices = torch.where(mask > 0)\n",
    "                        center_y = y_indices.float().mean()\n",
    "                        center_x = x_indices.float().mean()\n",
    "                    else:\n",
    "                        center_y = torch.rand(1, device=image.device) * image.shape[2]\n",
    "                        center_x = torch.rand(1, device=image.device) * image.shape[3]\n",
    "                    \n",
    "                    point_coords = torch.tensor([[center_x, center_y]], device=image.device)\n",
    "                    point_labels = torch.ones(1, device=image.device)\n",
    "                    \n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        sparse_embeddings, dense_embeddings = self.sam.prompt_encoder(\n",
    "                            points=(point_coords.unsqueeze(0), point_labels.unsqueeze(0)),\n",
    "                            boxes=None,\n",
    "                            masks=None\n",
    "                        )\n",
    "                        \n",
    "                        pos_encoding = self.sam.prompt_encoder.get_dense_pe()\n",
    "                        \n",
    "                        low_res_masks, _ = self.sam.mask_decoder(\n",
    "                            image_embeddings=curr_embeddings,\n",
    "                            image_pe=pos_encoding,\n",
    "                            sparse_prompt_embeddings=sparse_embeddings,\n",
    "                            dense_prompt_embeddings=dense_embeddings,\n",
    "                            multimask_output=False,\n",
    "                        )\n",
    "                        \n",
    "                        curr_mask = self.sam.postprocess_masks(\n",
    "                            low_res_masks,\n",
    "                            input_size=image.shape[-2:],\n",
    "                            original_size=image.shape[-2:]\n",
    "                        )\n",
    "                    \n",
    "                    instance_masks.append(curr_mask.squeeze())\n",
    "                    \n",
    "                    # Clear cache after each instance\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "            \n",
    "            if instance_masks:\n",
    "                image_masks = torch.stack(instance_masks, dim=0)\n",
    "            else:\n",
    "                image_masks = torch.zeros((num_instances, *image.shape[-2:]), device=image.device)\n",
    "            \n",
    "            final_masks.append(image_masks)\n",
    "            \n",
    "        output_masks = torch.stack(final_masks, dim=0)\n",
    "        return output_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9092280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:30.661508Z",
     "iopub.status.busy": "2024-12-13T18:12:30.660888Z",
     "iopub.status.idle": "2024-12-13T18:12:30.666378Z",
     "shell.execute_reply": "2024-12-13T18:12:30.665592Z"
    },
    "papermill": {
     "duration": 0.011355,
     "end_time": "2024-12-13T18:12:30.667999",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.656644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_sam():\n",
    "#     # Setup\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "#     # Use smaller image size\n",
    "#     image_size = (512, 512)  # Reduced from 1024x1024\n",
    "    \n",
    "#     # Transform\n",
    "#     transform = T.Compose([\n",
    "#         T.ToTensor(),\n",
    "#         T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "\n",
    "#     # Datasets\n",
    "#     train_dataset = UnderwaterInstanceDataset(\n",
    "#         root_dir=TRAIN_ROOT,\n",
    "#         ann_file=TRAIN_ANN,\n",
    "#         transform=transform,\n",
    "#         image_size=image_size\n",
    "#     )\n",
    "    \n",
    "#     val_dataset = UnderwaterInstanceDataset(\n",
    "#         root_dir=VAL_ROOT,\n",
    "#         ann_file=VAL_ANN,\n",
    "#         transform=transform,\n",
    "#         image_size=image_size\n",
    "#     )\n",
    "\n",
    "#     # Smaller batch size\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "#     model = SAMFinetune(CHECKPOINT_PATH).to(device)\n",
    "    \n",
    "#     # Initialize mixed precision training\n",
    "#     scaler = amp.GradScaler()\n",
    "    \n",
    "#     optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "#     scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
    "#     dice_loss = nn.BCEWithLogitsLoss()\n",
    "#     iou_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#     # Training loop\n",
    "#     best_val_loss = float('inf')\n",
    "#     num_epochs = 50\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         for batch_idx, (images, masks, labels) in enumerate(tqdm(train_loader)):\n",
    "#             images = images.to(device)\n",
    "#             masks = masks.to(device)\n",
    "            \n",
    "#             # Clear cache before each batch\n",
    "#             torch.cuda.empty_cache()\n",
    "#             gc.collect()\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             # Use mixed precision training\n",
    "#             with amp.autocast():\n",
    "#                 pred_masks = model(images, masks)\n",
    "#                 loss = dice_loss(pred_masks, masks) + iou_loss(pred_masks, masks)\n",
    "            \n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "            \n",
    "#             # Free up memory\n",
    "#             del pred_masks, loss\n",
    "#             torch.cuda.empty_cache()\n",
    "#             gc.collect()\n",
    "\n",
    "#         # Validation with reduced memory usage\n",
    "#         model.eval()\n",
    "#         val_loss = 0\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for images, masks, labels in val_loader:\n",
    "#                 images = images.to(device)\n",
    "#                 masks = masks.to(device)\n",
    "                \n",
    "#                 with amp.autocast():\n",
    "#                     pred_masks = model(images)\n",
    "#                     loss = dice_loss(pred_masks, masks) + iou_loss(pred_masks, masks)\n",
    "#                 val_loss += loss.item()\n",
    "                \n",
    "#                 del pred_masks, loss\n",
    "#                 torch.cuda.empty_cache()\n",
    "#                 gc.collect()\n",
    "\n",
    "#         avg_loss = total_loss / len(train_loader)\n",
    "#         avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "#         print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "#         print(f'Training Loss: {avg_loss:.4f}')\n",
    "#         print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "#             torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "#         scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735336b0",
   "metadata": {
    "papermill": {
     "duration": 0.003364,
     "end_time": "2024-12-13T18:12:30.675006",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.671642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2779dee",
   "metadata": {
    "papermill": {
     "duration": 0.003319,
     "end_time": "2024-12-13T18:12:30.681880",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.678561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1489235a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:30.689770Z",
     "iopub.status.busy": "2024-12-13T18:12:30.689492Z",
     "iopub.status.idle": "2024-12-13T18:12:30.693407Z",
     "shell.execute_reply": "2024-12-13T18:12:30.692668Z"
    },
    "papermill": {
     "duration": 0.009534,
     "end_time": "2024-12-13T18:12:30.694898",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.685364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def evaluate_sam(model):\n",
    "#     model.eval()\n",
    "    \n",
    "#     # Load validation dataset\n",
    "#     val_dataset = UnderwaterDataset(\n",
    "#         coco_annotation='/kaggle/input/underwaterimageinstancesegmentation/UIIS/UDW/annotations/val.json',\n",
    "#         img_dir='/kaggle/input/underwaterimageinstancesegmentation/UIIS/UDW/val',\n",
    "#         transform=transforms.Compose([\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "#                                std=[0.229, 0.224, 0.225])\n",
    "#         ])\n",
    "#     )\n",
    "    \n",
    "#     val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "#     # Metrics\n",
    "#     iou_scores = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, masks in tqdm(val_loader):\n",
    "#             images = images.to(DEVICE)\n",
    "#             masks = masks.to(DEVICE)\n",
    "            \n",
    "#             # Get predictions\n",
    "#             mask_predictions, _ = model(images, None)\n",
    "#             pred_masks = (torch.sigmoid(mask_predictions) > 0.5).float()\n",
    "            \n",
    "#             # Calculate IoU\n",
    "#             intersection = (pred_masks * masks).sum()\n",
    "#             union = pred_masks.sum() + masks.sum() - intersection\n",
    "#             iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "#             iou_scores.append(iou.item())\n",
    "    \n",
    "#     mean_iou = np.mean(iou_scores)\n",
    "#     print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    \n",
    "#     return mean_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e799c3d",
   "metadata": {
    "papermill": {
     "duration": 0.00339,
     "end_time": "2024-12-13T18:12:30.701867",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.698477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140717c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:30.709844Z",
     "iopub.status.busy": "2024-12-13T18:12:30.709611Z",
     "iopub.status.idle": "2024-12-13T18:12:30.712723Z",
     "shell.execute_reply": "2024-12-13T18:12:30.711966Z"
    },
    "papermill": {
     "duration": 0.008766,
     "end_time": "2024-12-13T18:12:30.714233",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.705467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trained_model = train_sam()\n",
    "# torch.save(trained_model.state_dict(), 'underwater_sam.pth')\n",
    "# mean_iou = evaluate_sam(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eebe6b8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:30.722325Z",
     "iopub.status.busy": "2024-12-13T18:12:30.722095Z",
     "iopub.status.idle": "2024-12-13T18:12:30.729061Z",
     "shell.execute_reply": "2024-12-13T18:12:30.728287Z"
    },
    "papermill": {
     "duration": 0.012747,
     "end_time": "2024-12-13T18:12:30.730633",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.717886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_sam(model):\n",
    "    model.eval()\n",
    "    \n",
    "    # Load validation dataset\n",
    "    val_dataset = UnderwaterInstanceDataset(\n",
    "        root_dir=VAL_ROOT,\n",
    "        ann_file=VAL_ANN,\n",
    "        transform=T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        image_size=(1024, 1024)\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "    \n",
    "    # Metrics\n",
    "    iou_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks, _ in tqdm(val_loader):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            pred_masks = model(images, masks)\n",
    "            pred_masks = (torch.sigmoid(pred_masks) > 0.5).float()\n",
    "            \n",
    "            # Calculate IoU for each instance\n",
    "            for i in range(masks.shape[1]):\n",
    "                if masks[:, i].sum() > 0:  # Only evaluate non-empty masks\n",
    "                    intersection = (pred_masks[:, i] * masks[:, i]).sum()\n",
    "                    union = pred_masks[:, i].sum() + masks[:, i].sum() - intersection\n",
    "                    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "                    iou_scores.append(iou.item())\n",
    "    \n",
    "    mean_iou = np.mean(iou_scores)\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"Number of instances evaluated: {len(iou_scores)}\")\n",
    "    \n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8787c0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:12:30.738652Z",
     "iopub.status.busy": "2024-12-13T18:12:30.738389Z",
     "iopub.status.idle": "2024-12-13T18:26:52.727256Z",
     "shell.execute_reply": "2024-12-13T18:26:52.726110Z"
    },
    "papermill": {
     "duration": 861.994664,
     "end_time": "2024-12-13T18:26:52.728877",
     "exception": false,
     "start_time": "2024-12-13T18:12:30.734213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating pretrained SAM model...\n",
      "loading annotations into memory...\n",
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/691 [00:00<?, ?it/s]/tmp/ipykernel_23/3964563570.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3964563570.py:60: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "100%|██████████| 691/691 [14:03<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU: 0.6363\n",
      "Number of instances evaluated: 3784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6362520139296935"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create and load model\n",
    "    model = SAMFinetune(CHECKPOINT_PATH).to(device)\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(\"Evaluating pretrained SAM model...\")\n",
    "    evaluate_sam(model)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6244847,
     "sourceId": 10120631,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 184761,
     "modelInstanceId": 162411,
     "sourceId": 190514,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 879.82789,
   "end_time": "2024-12-13T18:26:54.183116",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-13T18:12:14.355226",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
